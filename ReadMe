Here is a **clean, production-quality README** you can directly use in your repository.

---

# Industrial ESG Excel Parser

AI-powered Excel ingestion system for messy industrial data

---

## 1. Overview

This project is a **FastAPI-based Excel ingestion and validation system** designed for messy industrial ESG datasets.

Industrial Excel files often contain:

* Title rows
* Abbreviated headers
* Multiple assets per sheet
* Mixed formats (e.g., `"1,200"`, `"90%"`)
* Empty rows
* Inconsistent column naming

This system:

* Detects the header row automatically
* Uses LLM-based fuzzy mapping for column understanding
* Parses values into clean numeric formats
* Validates domain constraints
* Flags uncertain data for human review
* Outputs structured JSON ready for analytics pipelines

---

## 2. Architecture

```
Excel Upload
     ↓
Header Detection
     ↓
LLM Column Mapping
     ↓
Chunk Processing
     ↓
Value Parsing
     ↓
Validation Rules
     ↓
Structured JSON Output
```

### Core Components

* **FastAPI** – API server
* **LLM Mapping Layer** – Gemini-based column understanding
* **Chunk Processor** – Memory-efficient row processing
* **Value Parser** – Handles commas, %, nulls
* **Validation Layer** – Detects anomalies
* **Human Review Queue** – Flags uncertain fields

---

## 3. Features

### ✅ Header Row Detection

Automatically identifies the true header row even if the sheet contains title rows above it.

### ✅ Fuzzy Column Mapping

Maps abbreviated headers like:

* `Coal Cons`
* `Steam Gen`
* `Eff %`

to canonical parameters:

* `coal_consumption`
* `steam_generation`
* `efficiency`

### ✅ Multi-Asset Support

Supports Excel files where:

* One parameter appears for multiple assets
* Asset name is embedded in column header

Example:

```
Coal AFBC-1 | Coal AFBC-2
```

### ✅ Robust Value Parsing

Converts:

* `"1,200"` → `1200`
* `"90%"` → `0.9`
* `"--"` → `null`

### ✅ Validation & Data Quality Checks

Flags:

* Negative coal consumption
* Efficiency > 1
* Missing asset metadata
* Null critical parameters

### ✅ Human Review Detection

If:

* `param_name` is null
* Confidence is low
* Column meaning unclear

Data is pushed to:

```json
"human_review_required": []
```

---

## 4. API Endpoint

### POST `/upload`

Upload Excel file for processing.

### Example Request

Use Swagger UI:

```
http://localhost:8000/docs
```

Upload:

* messy_data.xlsx
* multi_asset.xlsx

---

## 5. Example Output Structure

```json
{
  "status": "success",
  "header_row": 5,
  "parsed_data": [
    {
      "row": 8,
      "col": 0,
      "param_name": "coal_consumption",
      "asset_name": "AFBC-1",
      "raw_value": "-500",
      "parsed_value": -500,
      "confidence": "high"
    }
  ],
  "warnings": [
    "Negative coal consumption detected"
  ],
  "human_review_required": [
    {
      "col": 6,
      "reason": "Unknown parameter"
    }
  ]
}
```

---

## 6. Assumptions

* Efficiency must be between 0 and 1
* Coal consumption cannot be negative
* Steam generation cannot be negative
* Empty rows are ignored
* Files are `.xlsx` format

---

## 7. Validation Rules

| Parameter        | Rule          |
| ---------------- | ------------- |
| coal_consumption | ≥ 0           |
| steam_generation | ≥ 0           |
| efficiency       | 0 ≤ value ≤ 1 |

Violations are pushed into `warnings`.

---

## 8. Running Locally

### 1. Clone repository

```bash
git clone <repo_url>
cd industrial-esg-parser
```

### 2. Create virtual environment

```bash
python -m venv venv
venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Run server

```bash
uvicorn app.main:app --reload
```

Open:

```
http://localhost:8000/docs
```

---

## 9. Running with Docker

### Build Image

```bash
docker build -t esg-parser .
```

### Run Container

```bash
docker run -p 8000:8000 esg-parser
```

Access Swagger:

```
http://localhost:8000/docs
```

---

## 10. Design Decisions

### Chunk Processing

Rows are processed in chunks to:

* Prevent memory overload
* Enable future parallelization

### LLM-Based Mapping

Used for:

* Handling abbreviated headers
* Handling inconsistent naming
* Handling multi-asset columns

Fallback logic exists if LLM fails.

### Human Review Queue

Instead of silently failing:

* Uncertain mappings are flagged
* Keeps system safe for production use

---

## 11. Test Data Files

Included:

* `messy_data.xlsx`

  * Abbreviated headers
  * Empty rows
  * Mixed formats

* `multi_asset.xlsx`

  * Multiple assets per parameter
  * Parameter deduplication test

Generate using:

```bash
cd data_generator
python messy_data.py
```

---

## 12. Limitations

* Only `.xlsx` supported
* Does not yet persist to database
* Does not include async batch processing
* LLM cost not optimized

---

## 13. Future Improvements

* Add PostgreSQL persistence
* Add background job queue
* Add monitoring & logging
* Add schema versioning
* Add automatic imputation
* Add anomaly detection using ML

---

## 14. Tech Stack

* Python 3.12
* FastAPI
* Pandas
* OpenPyXL
* Google Gemini (LLM Mapping)
* Docker

---

## 15. Author

Built as part of an AI internship technical evaluation
Focused on real-world industrial ESG data ingestion challenges.

